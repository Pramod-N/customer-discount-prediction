{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackingRegressor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1ePmeMVch+r56jKFCitG6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypsClMs8f9Xy",
        "outputId": "e8c93d5a-ecac-4c4f-885f-ef1cda12c491"
      },
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import requests, zipfile, io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  \"Since version 1.0, \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1MlP2fQgmqa"
      },
      "source": [
        "#convert the datetime column to number of days since previous order\n",
        "train_df['Last_order_placed_date'] = pd.to_datetime(train_df['Last_order_placed_date'])\n",
        "\n",
        "train_df['Days_since_last_order'] = (datetime.datetime.now() - train_df['Last_order_placed_date']).dt.days"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSjsIlw1hM2y"
      },
      "source": [
        "#drop columns \n",
        "train_df = train_df.drop(columns=['Last_order_placed_date','Customer_ID','No_of_issues_raised'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNTej-DMhRhB"
      },
      "source": [
        "conversion_names = {\n",
        "          \"Category_of_customers\" : {\"Active\" : 2, \"Inactive\":0,\"Passive\":1},\n",
        "          \"Premium_membership\" : {\"Yes\" : 1, \"No\":0}\n",
        "}\n",
        "train_df.replace(conversion_names,inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJvUUFqyhWcy"
      },
      "source": [
        "X = train_df.drop('Discount_percentage',axis=1)\n",
        "y = train_df['Discount_percentage']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0ddOaOJhXTR"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtRpJEFoLfpM"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBtbVGtohafR"
      },
      "source": [
        "xgbst_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
        "             max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
        "             n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
        "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "             silent=None, subsample=1, verbosity=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dWho6UhjZEZ",
        "outputId": "eddd0c50-4654-4358-9c69-cbf65814b8ed"
      },
      "source": [
        "#train the model on the train set\n",
        "xgbst_model.fit(X_train,y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(max_depth=6, objective='reg:squarederror')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJZI8RQHje5p"
      },
      "source": [
        "#Predict the output on both test & train set\n",
        "\n",
        "yhat_xgbstval = xgbst_model.predict(X_test)\n",
        "\n",
        "yhat_xgbsttrain = xgbst_model.predict(X_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC5vyGdGjf6S",
        "outputId": "b2510e1b-5841-4718-f04a-0b6a10f04be5"
      },
      "source": [
        "#Predict the r2Score for both test & train\n",
        "print(\"The score on the test set is:\",r2_score(y_test,yhat_xgbstval)*100)\n",
        "\n",
        "print(\"The score on the train set is:\",r2_score(y_train,yhat_xgbsttrain)*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on the test set is: 53.317353006183765\n",
            "The score on the train set is: 58.215680670064465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFlRGMpFLwQr"
      },
      "source": [
        "## HistBooster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07-NAZVuoxiZ"
      },
      "source": [
        "#Build the model\n",
        "histmodel = HistGradientBoostingRegressor(learning_rate=0.09)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xReL492eo6II",
        "outputId": "daedcaa1-9d24-400b-b597-0c250022479d"
      },
      "source": [
        "#train the model on the train set\n",
        "histmodel.fit(X_train,y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HistGradientBoostingRegressor(learning_rate=0.09)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm-Jf5Wio9zI"
      },
      "source": [
        "#Predict the output on both test & train set\n",
        "\n",
        "yhist_val = histmodel.predict(X_test)\n",
        "\n",
        "yhist_train = histmodel.predict(X_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH_S0X1qo-kY",
        "outputId": "75c4c7ae-1fc2-44ec-f14f-d726b37eda04"
      },
      "source": [
        "#Predict the r2Score for both test & train\n",
        "print(\"The score on the test set is:\",r2_score(y_test,yhist_val)*100)\n",
        "\n",
        "print(\"The score on the train set is:\",r2_score(y_train,yhist_train)*100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on the test set is: 53.431551192142216\n",
            "The score on the train set is: 56.4802279771092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hHiIsesMKWs"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUuXiRDQpBPw"
      },
      "source": [
        "#Build the model\n",
        "lgbmodel = LGBMRegressor(learning_rate=0.09)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9sFvHMDpPQw",
        "outputId": "6b724415-688a-48a2-fc70-08092955cd76"
      },
      "source": [
        "#Train the model on the train set\n",
        "lgbmodel.fit(X_train,y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(learning_rate=0.09)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNjC-c6-pRMQ"
      },
      "source": [
        "#Predict the output on both test and train set\n",
        "\n",
        "ylgb_val = lgbmodel.predict(X_test)\n",
        "\n",
        "ylgb_train = lgbmodel.predict(X_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0csiiQpLpTYw",
        "outputId": "acbdba95-0265-42c3-9f40-a1eb92908092"
      },
      "source": [
        "#Predict the r2Score for both test & train\n",
        "print(\"The score on the test set is:\",r2_score(y_test,ylgb_val)*100)\n",
        "\n",
        "print(\"The score on the train set is:\",r2_score(y_train,ylgb_train)*100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on the test set is: 53.18077648568843\n",
            "The score on the train set is: 58.02171303133687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmjTAuWmpYlw"
      },
      "source": [
        "## Stacking Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtbzOSklMO87"
      },
      "source": [
        "This is a form of model which has two levels of models. The first level can have multiple models trained on the set.\n",
        "For the model in the second level, the dataset is formed by taking the output of the models in the first level and considering them as features. \n",
        "\n",
        "The target variable remains the same for both levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ertLiiCvpd7I"
      },
      "source": [
        "level0 = list()\n",
        "\n",
        "#I have taken all 3 models shown above as my first level of models\n",
        "level0.append((\n",
        "    'xgbst',\n",
        "    XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
        "             max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
        "             n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
        "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "             silent=None, subsample=1, verbosity=1)\n",
        "    ))\n",
        "\n",
        "level0.append((\n",
        "    'histbst',\n",
        "    HistGradientBoostingRegressor(learning_rate=0.09)\n",
        "    ))\n",
        "\n",
        "level0.append((\n",
        "    'lgbbst',\n",
        "    LGBMRegressor(learning_rate=0.09)\n",
        "    ))\n",
        "\n",
        "#For the second level i have applied Linear Regression\n",
        "level1 = LinearRegression()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2deJjV5qFEf"
      },
      "source": [
        "#Build the Stacking Regressor\n",
        "meta_model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAWPXsJbqBkR",
        "outputId": "160719f1-555d-4392-9ac4-d72f250c35f4"
      },
      "source": [
        "#Train the model\n",
        "meta_model.fit(X_train,y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingRegressor(cv=5,\n",
              "                  estimators=[('xgbst',\n",
              "                               XGBRegressor(max_depth=6,\n",
              "                                            objective='reg:squarederror')),\n",
              "                              ('histbst',\n",
              "                               HistGradientBoostingRegressor(learning_rate=0.09)),\n",
              "                              ('lgbbst', LGBMRegressor(learning_rate=0.09))],\n",
              "                  final_estimator=LinearRegression())"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6oleYnDqRKy"
      },
      "source": [
        "#Predict the final result on validation and train set\n",
        "y_pred = meta_model.predict(X_test)\n",
        "\n",
        "ylrtrain_pred = meta_model.predict(X_train)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQwAXQQJqT2I",
        "outputId": "04cb58ab-ae31-42a5-e22c-31ff315d97ca"
      },
      "source": [
        "#Predict the r2Score for both test & train\n",
        "print(\"The score on the test set is:\",r2_score(y_test,y_pred)*100)\n",
        "\n",
        "print(\"The score on the train set is:\",r2_score(y_train,ylrtrain_pred)*100)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on the test set is: 53.4371118733708\n",
            "The score on the train set is: 57.7485164525899\n"
          ]
        }
      ]
    }
  ]
}