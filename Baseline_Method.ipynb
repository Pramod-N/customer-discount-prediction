{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Method.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZRPcw3w/fZgGaRkxKGhji"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKgCFEX0pThi",
        "outputId": "1d6f82cc-de23-4f57-be10-a31ced88b1cd"
      },
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import requests, zipfile, io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from lightgbm import LGBMRegressor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  \"Since version 1.0, \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA2V3lfzxju_"
      },
      "source": [
        "Note: I have not exposed the link to read dataset. Whoever wants to use this code, please reach out to me on my email(please check overivew page), so that i can share the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzGE83Wuqosg"
      },
      "source": [
        "Convert the Datetime column to as Number of Days from previous order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSAS3vPR62_o"
      },
      "source": [
        "train_df['Last_order_placed_date'] = pd.to_datetime(train_df['Last_order_placed_date'])\n",
        "\n",
        "train_df['Days_since_last_order'] = (datetime.datetime.now() - train_df['Last_order_placed_date']).dt.days"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhQQCnBRrCFA"
      },
      "source": [
        "From EDA (check EDA file code), we get to know that the feature No_of_Orders_Placed and No_of_issue_raised are exactly same. So we can drop them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTbjvIqGqz7A"
      },
      "source": [
        "train_df = train_df.drop(columns=['Last_order_placed_date','Customer_ID','No_of_issues_raised'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x721AlCOrdJY"
      },
      "source": [
        "Assign the categorical and Ordinal columns to a numeric value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLComUqXrbNA"
      },
      "source": [
        "conversion_names = {\n",
        "          \"Category_of_customers\" : {\"Active\" : 2, \"Inactive\":0,\"Passive\":1},\n",
        "          \"Premium_membership\" : {\"Yes\" : 1, \"No\":0}\n",
        "}\n",
        "train_df.replace(conversion_names,inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ-RcY4froHY"
      },
      "source": [
        "#separate the data into input features and output prediction\n",
        "X = train_df.drop('Discount_percentage',axis=1)\n",
        "y = train_df['Discount_percentage']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zazeDHDGsCKf"
      },
      "source": [
        "#split the data into train-test set(20% test data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ReYCCxs4jA"
      },
      "source": [
        "Below code contains three tree based - XGBOOST, HISTBOOSTER & LIGHTGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2FVcoAjshN_"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo0uIKf7sjY3"
      },
      "source": [
        "#Build the model\n",
        "xgbst_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
        "             max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
        "             n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
        "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "             silent=None, subsample=1, verbosity=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18G9ExHos1aA",
        "outputId": "d590576e-8d46-4ba3-a28e-b6264d944878"
      },
      "source": [
        "#train the model on the train set\n",
        "xgbst_model.fit(X_train,y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(max_depth=5, objective='reg:squarederror')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvomMJJEtKC_"
      },
      "source": [
        "#Predict the output on both test & train set\n",
        "\n",
        "yhat_xgbstval = xgbst_model.predict(X_test)\n",
        "\n",
        "yhat_xgbsttrain = xgbst_model.predict(X_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr9c8O75tbnH",
        "outputId": "cef605a6-1f5a-4b63-c76d-d8db6005a0a2"
      },
      "source": [
        "#Predict the r2Score for both test & train\n",
        "print(\"The score on the test set is:\",r2_score(y_test,yhat_xgbstval)*100)\n",
        "\n",
        "print(\"The score on the train set is:\",r2_score(y_train,yhat_xgbsttrain)*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on the test set is: 53.23083453097005\n",
            "The score on the train set is: 56.64031236884467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPa2qdMluc7Z"
      },
      "source": [
        "## HistBooster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2M77BrHuehP"
      },
      "source": [
        "#Build the model\n",
        "histmodel = HistGradientBoostingRegressor(learning_rate=0.09)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmstNAamu5i_",
        "outputId": "da5c74a3-d56e-428c-9ea8-555d4b62a84d"
      },
      "source": [
        "#train the model on the train set\n",
        "histmodel.fit(X_train,y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HistGradientBoostingRegressor(learning_rate=0.09)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo_Pqpsfu-co"
      },
      "source": [
        "#Predict the output on both test & train set\n",
        "\n",
        "yhist_val = histmodel.predict(X_test)\n",
        "\n",
        "yhist_train = histmodel.predict(X_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzysPrn-vH2o",
        "outputId": "d9202f0e-df20-41a6-ecbc-d2cf97a3717d"
      },
      "source": [
        "#Predict the r2Score for both test & train\n",
        "print(\"The score on the test set is:\",r2_score(y_test,yhist_val)*100)\n",
        "\n",
        "print(\"The score on the train set is:\",r2_score(y_train,yhist_train)*100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on the test set is: 53.47476147933061\n",
            "The score on the train set is: 56.70578361751312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M6CIbb2vhwB"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf5j0qMRvkGf"
      },
      "source": [
        "#Build the model\n",
        "lgbmodel = LGBMRegressor(learning_rate=0.09)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edZGzmCqv2E3",
        "outputId": "2460cb3e-7768-4787-efe0-dd3461040ba6"
      },
      "source": [
        "#Train the model on the train set\n",
        "lgbmodel.fit(X_train,y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(learning_rate=0.09)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUncU51Gv4HZ"
      },
      "source": [
        "#Predict the output on both test and train set\n",
        "\n",
        "ylgb_val = lgbmodel.predict(X_test)\n",
        "\n",
        "ylgb_train = lgbmodel.predict(X_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiAXgIPJv4zf",
        "outputId": "e933b4dd-f9ae-4fa5-b8fe-bc32c5df9254"
      },
      "source": [
        "#Predict the r2Score for both test & train\n",
        "print(\"The score on the test set is:\",r2_score(y_test,ylgb_val)*100)\n",
        "\n",
        "print(\"The score on the train set is:\",r2_score(y_train,ylgb_train)*100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on the test set is: 53.35156564777446\n",
            "The score on the train set is: 58.01768506262549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvgnVB49wjTR"
      },
      "source": [
        "## Averaging All three Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mHyZpruwnPP"
      },
      "source": [
        "#Averaging prediction on test and train set\n",
        "pred_val =  (ylgb_val + yhist_val + yhat_xgbstval)/3\n",
        "\n",
        "pred_train = (ylgb_train + yhist_train + yhat_xgbsttrain)/3"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqVnlS0UxKKX",
        "outputId": "4bac062e-823d-4288-e394-7aaa521ca75b"
      },
      "source": [
        "#Predict the final r2Score for both test & train\n",
        "print(\"The score on the test set is:\",r2_score(y_test,pred_val)*100)\n",
        "\n",
        "print(\"The score on the train set is:\",r2_score(y_train,pred_train)*100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score on the test set is: 53.4881633254732\n",
            "The score on the train set is: 57.26144712595818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuvBwQFDxTHI"
      },
      "source": [
        "we observe that on averaging the models, the validation set or the test set accuracy improves. "
      ]
    }
  ]
}